{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5351,"status":"ok","timestamp":1743444354645,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"},"user_tz":-330},"id":"JtI0Yc-KYVTO","outputId":"6f32b32c-aea1-4ead-d3a9-5ce40f16cad8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]}],"source":["!pip install pandas openpyxl\n"]},{"cell_type":"markdown","metadata":{"id":"4B5l8P4INaNP"},"source":["**Step 2**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ytu2d1DOZOOV","executionInfo":{"status":"ok","timestamp":1743622232305,"user_tz":-330,"elapsed":625557,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"ddb133c4-8dec-42a4-999c-8cc195fa5c87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cleaned data saved to cleaned_data_final.xlsx\n"]}],"source":["import pandas as pd\n","\n","# Load the Excel file with the second row as header\n","file_path = 'cleaned_data_1.xlsx'  # Replace with your actual file path\n","df = pd.read_excel(file_path)  # Set header=1 to use the second row as column names\n","\n","# Specify the column to clean\n","column_to_clean = \"LR.RESULT_VALUE||(CASEWHENDBMS_LOB.GETLENGTH(LRP.RESULTVALUE)>3000THEN'/***********DATATRUNCATED***********/'||TO_CHAR(DBMS_LOB.SUBSTR(LRP.RESULTVALUE,3000,1))||'/***********DATATRUNCATED***********/'ELSETO_CHAR(LRP.RESULTVALUE)END)||(CASEWHENLR.RESUL\"\n","\n","# Step 1: Remove rows where the column contains blank spaces or any alphabetic characters\n","df = df[~df[column_to_clean].str.contains(r'[a-zA-Z\\s]', na=False)]\n","\n","# Step 2: Remove rows where the specified column is empty or NaN\n","df = df[df[column_to_clean].notna() & (df[column_to_clean].str.strip() != '')]\n","\n","# Step 3: Remove rows where the column contains '/', '-', '+', '<', '>', or ':'\n","df = df[~df[column_to_clean].str.contains(r'[\\/\\-\\+<>:]', na=False)]\n","\n","# Save the cleaned data to a new Excel file\n","output_file_path = 'cleaned_data_final.xlsx'\n","df.to_excel(output_file_path, index=False)\n","\n","print(f\"Cleaned data saved to {output_file_path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"Jo5Z5RMvNegf"},"source":["**Step 3**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253885,"status":"ok","timestamp":1743622937935,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"},"user_tz":-330},"id":"mIVosO3oa7E4","outputId":"59e40f7d-2d96-4849-df86-0a91f8dc5383"},"outputs":[{"output_type":"stream","name":"stdout","text":["['MRNO', \"PM.PREFIX||''||P.PATIENTNAME\", 'AGE', 'LOOKUPVALUE', 'VISITID', 'PATIENT_VISIT_ID', 'ADMISSIONNUMBER', 'LAB_ORDER_ID', 'GROUPID', 'BILLING_GROUP', 'GROUPNAME', 'DEPARTMENT_ID', 'DEPARTMENT_CODE', 'DEPARTMENT_NAME', 'EMPLOYEE_ID', 'EMPNO', \"EMPPM.PREFIX||''||EMP.FIRSTNAME||''||EMP.MIDDLENAME||''||EMP.LASTNAME\", 'PROFILE_CODE', 'PROFILE_NAME', 'SERVICE_MASTER_ID', 'SERVICE_CODE', 'SERVICE_NAME', 'INVESTIGATIONPARAMETERNAME', \"LR.RESULT_VALUE||(CASEWHENDBMS_LOB.GETLENGTH(LRP.RESULTVALUE)>3000THEN'/***********DATATRUNCATED***********/'||TO_CHAR(DBMS_LOB.SUBSTR(LRP.RESULTVALUE,3000,1))||'/***********DATATRUNCATED***********/'ELSETO_CHAR(LRP.RESULTVALUE)END)||(CASEWHENLR.RESUL\", '(CASEWHENLR.RESULT_TYPE_ID=1099THENTO_CHAR(LRP.RESULTRANGE)ELSELR.REFERENCE_RANGEEND)', \"TO_CHAR(SO.PROCESSED_DATE_TIME,'YYYY/MM/DD')\", \"TO_CHAR(LO.ORDERED_DATE,'YYYY/MM/DD')\"]\n"]}],"source":["\n","import pandas as pd\n","\n","# Read the Excel file with headers from the second row\n","df = pd.read_excel('cleaned_data_final.xlsx')\n","\n","# Now proceed with your data processing\n","print(df.columns.tolist())  # Verify the column names\n","\n","# Define the id columns based on your data structure\n","id_columns = ['MRNO', 'PM.PREFIX||\\'\\'||P.PATIENTNAME', 'AGE', 'LOOKUPVALUE', 'VISITID', 'PATIENT_VISIT_ID', 'ADMISSIONNUMBER']\n","\n","# Group by the identifier columns and aggregate the rest\n","df_grouped = df.groupby(id_columns, as_index=False).agg(lambda x: ' | '.join(x.dropna().astype(str)))\n","\n","# Save the result to a new CSV file\n","df_grouped.to_csv('output_fixed_data.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"AV4m3e4oNiQ3"},"source":["**Step 4**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1655,"status":"ok","timestamp":1743623113154,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"},"user_tz":-330},"id":"R_UE_q7vnRQr","outputId":"2360f830-5245-4690-df69-d922fcc62fb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cleaned data saved to filtered_data.csv\n"]}],"source":["import pandas as pd\n","\n","# Load the CSV file\n","# Replace 'input_file.csv' with the actual path to your CSV file\n","file_path = 'output_fixed_data.csv'  # Update this with your file name if needed\n","df = pd.read_csv(file_path)\n","\n","# Define the columns to remove\n","columns_to_remove = [\n","    \"PM.PREFIX||''||P.PATIENTNAME\", \"VISITID\", \"PATIENT_VISIT_ID\", \"ADMISSIONNUMBER\",\n","    \"LAB_ORDER_ID\", \"GROUPID\", \"BILLING_GROUP\", \"GROUPNAME\", \"DEPARTMENT_ID\",\n","    \"DEPARTMENT_CODE\", \"DEPARTMENT_NAME\", \"EMPLOYEE_ID\", \"EMPNO\",\n","    \"EMPPM.PREFIX||''||EMP.FIRSTNAME||''||EMP.MIDDLENAME||''||EMP.LASTNAME\",\n","    \"PROFILE_CODE\", \"PROFILE_NAME\", \"SERVICE_MASTER_ID\", \"SERVICE_CODE\", \"SERVICE_NAME\", \"(CASEWHENLR.RESULT_TYPE_ID=1099THENTO_CHAR(LRP.RESULTRANGE)ELSELR.REFERENCE_RANGEEND)\",\n","    \"TO_CHAR(SO.PROCESSED_DATE_TIME,'YYYY/MM/DD')\",\n","    \"TO_CHAR(LO.ORDERED_DATE,'YYYY/MM/DD')\"\n","]\n","\n","# Remove the specified columns\n","df_cleaned = df.drop(columns=columns_to_remove, errors='ignore')\n","\n","# Save the cleaned dataframe to a new CSV file\n","output_file_path = 'filtered_data.csv'\n","df_cleaned.to_csv(output_file_path, index=False)\n","\n","print(f\"Cleaned data saved to {output_file_path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"5GZrPpudNVsr"},"source":["**Step 1**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":463102,"status":"ok","timestamp":1743621493588,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"},"user_tz":-330},"id":"R3AnfWbxo0_w","outputId":"4712b7af-4f9a-4207-e5f5-fedcbb8f6e74"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-33-1f95a3b539d8>:10: DtypeWarning: Columns (15,22) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file_path)\n"]},{"output_type":"stream","name":"stdout","text":["Processed file saved as cleaned_data_1.xlsx\n"]}],"source":["import pandas as pd\n","import re\n","import datetime\n","\n","# Load the Excel file\n","file_path = 'Feb.csv'\n","output_file = 'cleaned_data_1.xlsx'\n","\n","# Read the Excel file\n","df = pd.read_csv(file_path)\n","\n","# Define a pattern to match date formats like '1900-01-01 01:40:00' or '2025-10-05 00:00:00'\n","date_pattern = re.compile(r'^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}$')\n","\n","# Function to check if a value is a date string\n","def is_date(value):\n","    if not isinstance(value, str):\n","        return False\n","    return bool(date_pattern.match(value))\n","\n","# Function to process each cell\n","def process_cell(value):\n","    if pd.isna(value):\n","        return value\n","\n","    # Convert to string for checking\n","    str_value = str(value)\n","\n","    # Check if it's a date format\n","    if is_date(str_value):\n","        return '-'\n","\n","    # Return original value if not a date\n","    return value\n","\n","# Apply the function to the problematic column\n","column_name = \"LR.RESULT_VALUE||(CASEWHENDBMS_LOB.GETLENGTH(LRP.RESULTVALUE)>3000THEN'/***********DATATRUNCATED***********/'||TO_CHAR(DBMS_LOB.SUBSTR(LRP.RESULTVALUE,3000,1))||'/***********DATATRUNCATED***********/'ELSETO_CHAR(LRP.RESULTVALUE)END)||(CASEWHENLR.RESUL\"\n","\n","# Process all columns in case the column name is different or there are other columns with dates\n","for column in df.columns:\n","    df[column] = df[column].apply(process_cell)\n","\n","# Save the processed dataframe to a new Excel file\n","df.to_excel(output_file, index=False)\n","\n","print(f\"Processed file saved as {output_file}\")"]},{"cell_type":"markdown","metadata":{"id":"FHZJJGFTNk2f"},"source":["**Step 5**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1078,"status":"ok","timestamp":1743623121535,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"},"user_tz":-330},"id":"7_hEzMn72tPk","outputId":"838be75f-d977-4a86-e553-d44bb0689f17"},"outputs":[{"output_type":"stream","name":"stdout","text":["Transformed data saved to transformed_data.csv\n"]}],"source":["import pandas as pd\n","\n","# Load the CSV file\n","file_path = 'filtered_data.csv'  # Replace with your actual file path\n","df = pd.read_csv(file_path)\n","\n","# Specify the columns to work with\n","parameters_column = \"INVESTIGATIONPARAMETERNAME\"\n","values_column = \"LR.RESULT_VALUE||(CASEWHENDBMS_LOB.GETLENGTH(LRP.RESULTVALUE)>3000THEN'/***********DATATRUNCATED***********/'||TO_CHAR(DBMS_LOB.SUBSTR(LRP.RESULTVALUE,3000,1))||'/***********DATATRUNCATED***********/'ELSETO_CHAR(LRP.RESULTVALUE)END)||(CASEWHENLR.RESUL\"\n","\n","# Ensure all values in the columns are strings or lists; replace non-iterables with empty lists\n","df[parameters_column] = df[parameters_column].apply(lambda x: str(x).split(\" | \") if isinstance(x, str) else [])\n","df[values_column] = df[values_column].apply(lambda x: str(x).split(\" | \") if isinstance(x, str) else [])\n","\n","# Create a dictionary to hold parameter-value pairs for each row\n","expanded_data = []\n","\n","for _, row in df.iterrows():\n","    param_values = dict(zip(row[parameters_column], row[values_column]))\n","    expanded_data.append(param_values)\n","\n","# Convert the expanded data into a DataFrame\n","expanded_df = pd.DataFrame(expanded_data)\n","\n","# Concatenate the original DataFrame with the expanded DataFrame\n","result_df = pd.concat([df.drop(columns=[parameters_column, values_column]), expanded_df], axis=1)\n","\n","# Save the transformed DataFrame to a new CSV file\n","output_file_path = 'transformed_data.csv'\n","result_df.to_csv(output_file_path, index=False)\n","\n","print(f\"Transformed data saved to {output_file_path}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"79CgiJlDonhn"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMwA6VDKL5ABwKC8Byg2aIx"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}