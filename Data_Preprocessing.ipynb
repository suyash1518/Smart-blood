{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN4qenu4MlRbmedyk90nxkN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Step 6**"],"metadata":{"id":"kTIMxl6FyfAk"}},{"cell_type":"code","source":["# Calculate the number of filled rows for each column\n","\n","import pandas as pd\n","from datetime import datetime\n","\n","# Load the transformed dataset\n","file_path = 'transformed_data.csv'  # Replace with your actual file path\n","df = pd.read_csv(file_path)\n","\n","# Calculate the number of filled rows for each column\n","filled_rows = df.notna().sum()  # Count non-NaN values for each column\n","\n","# Convert the filled rows to a dictionary for appending as a new row\n","filled_rows_dict = filled_rows.to_dict()\n","\n","# Add the current date and time to the dictionary\n","current_datetime = datetime.now().strftime('%A, %B %d, %Y, %I:%M %p %Z')  # Format: Thursday, April 03, 2025, 12:35 PM IST\n","filled_rows_dict['Current Date'] = current_datetime\n","\n","# Append the new row to the DataFrame\n","df.loc[len(df)] = filled_rows_dict\n","\n","# Save the updated DataFrame to a new CSV file\n","output_file_path = 'updated_transformed_data.csv'\n","df.to_csv(output_file_path, index=False)\n","\n","print(f\"Updated data saved to {output_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHd_2B8zd93v","executionInfo":{"status":"ok","timestamp":1743675152732,"user_tz":-330,"elapsed":379,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"335f3b5c-6628-4445-9a21-8810067f2378"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated data saved to updated_transformed_data_1.csv\n"]}]},{"cell_type":"markdown","source":["**Step 7**"],"metadata":{"id":"qFFgUIV5yiJF"}},{"cell_type":"code","source":["# Filter columns with filled rows >= 4800 (Dec), 5000(Nov), 4800 (Feb) (Depends on the month)\n","\n","\n","import pandas as pd\n","\n","# Load the dataset\n","file_path = 'updated_transformed_data.csv'  # Replace with your actual file path\n","try:\n","    df = pd.read_csv(file_path)\n","\n","    # Calculate the number of filled rows for each column\n","    filled_rows = df.notna().sum()  # Count non-NaN values for each column\n","\n","    # Filter columns with filled rows >= Depends\n","    columns_to_keep = filled_rows[filled_rows >= 4800].index\n","    df_filtered = df[columns_to_keep]\n","\n","    # Save the filtered DataFrame to a new CSV file\n","    output_file_path = 'filtered_columns_data.csv'\n","    df_filtered.to_csv(output_file_path, index=False)\n","\n","    print(f\"Filtered data saved to {output_file_path}\")\n","except FileNotFoundError:\n","    print(f\"File not found: {file_path}. Please check the file path and try again.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ByYlokdieMti","executionInfo":{"status":"ok","timestamp":1743670725743,"user_tz":-330,"elapsed":254,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"147d6588-4ce4-4ad9-f657-57a1bd5daa10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Filtered data saved to filtered_columns_data.csv\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-381bdd6b125d>:9: DtypeWarning: Columns (37,50,63,122,133,200,201,203) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file_path)\n"]}]},{"cell_type":"markdown","source":["**Step 8**"],"metadata":{"id":"JYt2pOJ2ylwU"}},{"cell_type":"code","source":["# Remove empty rows\n","\n","import pandas as pd\n","\n","# Load the dataset\n","file_path = 'filtered_columns_data.csv'  # Replace with your actual file path\n","df = pd.read_csv(file_path)\n","\n","# Specify the columns to exclude from the emptiness check\n","exclude_columns = ['MRNO', 'AGE', 'LOOKUPVALUE']\n","\n","# Create a mask to identify rows where all columns except the excluded ones are empty\n","mask = df.drop(columns=exclude_columns).notna().any(axis=1)\n","\n","# Filter the DataFrame to retain only rows where the mask is True\n","df_filtered = df[mask]\n","\n","# Save the filtered DataFrame to a new CSV file\n","output_file_path = 'filtered_rows_data.csv'\n","df_filtered.to_csv(output_file_path, index=False)\n","\n","print(f\"Filtered data saved to {output_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"357H4jFWqL5A","executionInfo":{"status":"ok","timestamp":1743670960941,"user_tz":-330,"elapsed":235,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"9130acd6-67f9-4f1d-e1d8-211fe5b9f89b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Filtered data saved to filtered_rows_data.csv\n"]}]},{"cell_type":"markdown","source":["**Step 9**"],"metadata":{"id":"H7cD4WA1yrvI"}},{"cell_type":"code","source":["# Calculate the number of filled rows for each column again to help find error\n","\n","import pandas as pd\n","from datetime import datetime\n","\n","# Load the transformed dataset\n","file_path = 'filtered_rows_data.csv'  # Replace with your actual file path\n","df = pd.read_csv(file_path)\n","\n","# Calculate the number of filled rows for each column\n","filled_rows = df.notna().sum()  # Count non-NaN values for each column\n","\n","# Convert the filled rows to a dictionary for appending as a new row\n","filled_rows_dict = filled_rows.to_dict()\n","\n","# Add the current date and time to the dictionary\n","current_datetime = datetime.now().strftime('%A, %B %d, %Y, %I:%M %p %Z')  # Format: Thursday, April 03, 2025, 12:35 PM IST\n","filled_rows_dict['Current Date'] = current_datetime\n","\n","# Append the new row to the DataFrame\n","df.loc[len(df)] = filled_rows_dict\n","\n","# Save the updated DataFrame to a new CSV file\n","output_file_path = 'updated_transformed_data_1.csv'\n","df.to_csv(output_file_path, index=False)\n","\n","print(f\"Updated data saved to {output_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OgAwh7SErFrr","executionInfo":{"status":"ok","timestamp":1743670980936,"user_tz":-330,"elapsed":121,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"279ce283-5e6f-4f4d-ae06-73958c42514f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated data saved to updated_transformed_data_1.csv\n"]}]},{"cell_type":"markdown","source":["**Step 10**"],"metadata":{"id":"jFYVIPqICOZS"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# File paths for the datasets\n","files = [\n","    'Feb_updated_transformed_data_1.csv',\n","    'Dec_updated_transformed_data_1.csv',\n","    'Nov_updated_transformed_data_1.csv'\n","]\n","\n","# List to store processed DataFrames\n","dataframes = []\n","\n","# Process each file\n","for file in files:\n","    # Load the dataset\n","    df = pd.read_csv(file)\n","\n","    # Remove the last two rows\n","    df = df.iloc[:-2]\n","\n","    # Append the processed DataFrame to the list\n","    dataframes.append(df)\n","\n","# Merge all DataFrames on the first three columns (MRNO, AGE, LOOKUPVALUE)\n","merged_df = pd.concat(dataframes, ignore_index=True)\n","\n","# Save the merged DataFrame to a new CSV file\n","output_file_path = 'merged_data.csv'\n","merged_df.to_csv(output_file_path, index=False)\n","\n","print(f\"Merged data saved to {output_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YOXp_EJ7tEtJ","executionInfo":{"status":"ok","timestamp":1743672832103,"user_tz":-330,"elapsed":364,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"6f115f74-bfc2-44c6-880a-8cd9a589fdf6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Merged data saved to merged_data.csv\n"]}]},{"cell_type":"markdown","source":["**Step 11**"],"metadata":{"id":"52d5OIH5IKKR"}},{"cell_type":"code","source":["# Generate a unique alphanumeric ID for each row in the MRNO column\n","\n","import pandas as pd\n","import uuid\n","\n","# Load the dataset\n","file_path = 'merged_data.csv'  # Replace with your actual file path\n","df = pd.read_csv(file_path)\n","\n","# Generate a unique alphanumeric ID for each row in the MRNO column\n","df['MRNO'] = [f\"ID-{uuid.uuid4().hex[:8].upper()}\" for _ in range(len(df))]\n","\n","# Save the updated DataFrame to a new CSV file\n","output_file_path = 'updated_merged_data.csv'\n","df.to_csv(output_file_path, index=False)\n","\n","print(f\"Updated data saved to {output_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d-T1NDpP_-2d","executionInfo":{"status":"ok","timestamp":1743674190390,"user_tz":-330,"elapsed":420,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"6084caa2-f840-4c16-9356-fd9e6cb2ba8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated data saved to updated_merged_data.csv\n"]}]},{"cell_type":"markdown","source":["**Step 12**"],"metadata":{"id":"6fWArbEYJCA0"}},{"cell_type":"code","source":["# Calculate the percentage of missing values for each column\n","\n","import pandas as pd\n","\n","# Load the dataset\n","file_path = 'merged_data.csv'  # Replace with your actual file path\n","df = pd.read_csv(file_path)\n","\n","# Calculate the percentage of missing values for each column\n","missing_percentage = df.isna().mean() * 100  # Calculate percentage of NaN values\n","\n","# Convert the percentages to a dictionary for appending as a new row\n","missing_percentage_dict = missing_percentage.to_dict()\n","\n","# Add a label for the new row\n","missing_percentage_dict['MRNO'] = 'Missing Percentage'\n","\n","# Append the new row to the DataFrame\n","df.loc[len(df)] = missing_percentage_dict\n","\n","# Save the updated DataFrame to a new CSV file\n","output_file_path = 'updated_with_missing_percentage.csv'\n","df.to_csv(output_file_path, index=False)\n","\n","print(f\"Updated data with missing percentages saved to {output_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ym6Yz5RFKc3","executionInfo":{"status":"ok","timestamp":1743674621039,"user_tz":-330,"elapsed":335,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"8faac848-9d27-4f95-f405-4d821c954a18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated data with missing percentages saved to updated_with_missing_percentage.csv\n"]}]},{"cell_type":"markdown","source":["**Step 13**"],"metadata":{"id":"yeADtzTTJFfr"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.impute import KNNImputer\n","\n","# Load the dataset\n","file_path = \"updated_merged_data.csv\"\n","df = pd.read_csv(file_path)\n","\n","# Mean/Median Imputation for Numerical Columns\n","numerical_median_cols = ['MCHC', 'MCV', 'MCH', 'RBC COUNT', 'HAEMOGLOBIN', 'PCV',\n","                         'ABSOLUTE NEUTROPHIL COUNT', 'RDW-CV', 'PLATELET COUNT',\n","                         'ABSOLUTE MONOCYTE COUNT', 'ABSOLUTE EOSINOPHIL COUNT',\n","                         'ABSOLUTE BASOPHIL COUNT', 'ABSOLUTE LYMPHOCYTE COUNT']\n","\n","df[numerical_median_cols] = df[numerical_median_cols].fillna(df[numerical_median_cols].median())\n","\n","# Mode Imputation for Categorical-Like Columns\n","categorical_mode_cols = ['BASOPHIL', 'MONOCYTE', 'LYMPHOCYTE', 'EOSINOPHIL', 'NEUTROPHIL']\n","df[categorical_mode_cols] = df[categorical_mode_cols].fillna(df[categorical_mode_cols].mode().iloc[0])\n","\n","# KNN Imputation for Complex Dependencies (if needed)\n","knn_imputer = KNNImputer(n_neighbors=5)\n","df[numerical_median_cols] = knn_imputer.fit_transform(df[numerical_median_cols])\n","\n","# Save the cleaned dataset\n","cleaned_file_path = \"filled_data.csv\"\n","df.to_csv(cleaned_file_path, index=False)\n","\n","print(f\"Missing values handled! Filled dataset saved at: {cleaned_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EF_dNzrMGznI","executionInfo":{"status":"ok","timestamp":1743674922231,"user_tz":-330,"elapsed":1953,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"ff47791c-097a-4852-f6c6-0aaa89f800a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Missing values handled! Filled dataset saved at: filled_data.csv\n"]}]},{"cell_type":"markdown","source":["**Step 14**"],"metadata":{"id":"3nCgP177JTqv"}},{"cell_type":"code","source":["# Calculate the percentage of missing values for the whole dataset\n","\n","import pandas as pd\n","\n","# Load the dataset\n","file_path = 'updated_merged_data.csv'  # Replace with your actual file path\n","df = pd.read_csv(file_path)\n","\n","# Calculate the total number of cells in the dataset\n","total_cells = df.size\n","\n","# Calculate the total number of missing values in the dataset\n","missing_values = df.isna().sum().sum()\n","\n","# Calculate the percentage of missing values\n","missing_percentage = (missing_values / total_cells) * 100\n","\n","print(f\"Percentage of missing values in the entire dataset: {missing_percentage:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5YWXN3QLH8v8","executionInfo":{"status":"ok","timestamp":1743675265799,"user_tz":-330,"elapsed":71,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"e24172ad-47fd-4bb9-ed9d-9c9dc31ee0d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Percentage of missing values in the entire dataset: 0.59%\n"]}]},{"cell_type":"markdown","source":["**Step 15**"],"metadata":{"id":"5uK4Ynm82oYY"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the dataset\n","file_path = 'filled_data.csv'  # Replace with your actual file path\n","df = pd.read_csv(file_path)\n","\n","# Define the columns and their respective multiplication factors\n","columns_to_multiply = {\n","    'ABSOLUTE NEUTROPHIL COUNT': 1000,\n","    'WBC COUNT': 1000,\n","    'PLATELET COUNT': 1000,\n","    'ABSOLUTE LYMPHOCYTE COUNT': 1000\n","}\n","\n","# Multiply the specified columns by their respective factors\n","for column, factor in columns_to_multiply.items():\n","    if column in df.columns:  # Check if the column exists in the dataset\n","        df[column] = df[column].apply(lambda x: x * factor if pd.notna(x) else x)\n","\n","# Save the updated DataFrame to a new CSV file\n","output_file_path = 'updated_filled_data.csv'\n","df.to_csv(output_file_path, index=False)\n","\n","print(f\"Updated data saved to {output_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4ZGLOXCNPmk","executionInfo":{"status":"ok","timestamp":1743697409268,"user_tz":-330,"elapsed":457,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"9ab34e99-0022-413d-e3a0-e1fbbe41731c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated data saved to updated_filled_data.csv\n"]}]},{"cell_type":"markdown","source":["**Step 16**"],"metadata":{"id":"-AbP7JDF2qtW"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the dataset\n","file_path = 'updated_filled_data.csv'  # Replace with your actual file path\n","df = pd.read_csv(file_path)\n","\n","# Format all numeric columns to remove unnecessary decimal places\n","df = df.round(2)  # Round all numeric columns to 2 decimal places\n","\n","# Save the updated DataFrame to a new CSV file\n","output_file_path = 'formatted_data.csv'\n","df.to_csv(output_file_path, index=False)\n","\n","print(f\"Formatted data saved to {output_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XdReEwa7eLTH","executionInfo":{"status":"ok","timestamp":1743697735918,"user_tz":-330,"elapsed":439,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"8af93cd4-9b0e-4fd6-e002-ef622dcf7215"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Formatted data saved to formatted_data.csv\n"]}]},{"cell_type":"markdown","source":["**Step 17**"],"metadata":{"id":"3cccxvX52tAg"}},{"cell_type":"code","source":["import pandas as pd\n","\n","def detect_diseases(df):\n","    conditions = []\n","\n","    for _, row in df.iterrows():\n","        detected = []\n","\n","        # Iron Deficiency Anemia\n","        if row['HAEMOGLOBIN'] < 12 and row['MCV'] < 80 and row['MCH'] < 27 and row['MCHC'] < 32 and row['RBC COUNT'] < 4.2 and row['RDW-CV'] > 15:\n","            detected.append(\"Iron Deficiency Anemia\")\n","\n","        # Hemolytic Anemia\n","        if row['HAEMOGLOBIN'] < 12 and row['RBC COUNT'] < 4.2 and row['RDW-CV'] > 15:\n","            detected.append(\"Hemolytic Anemia\")\n","\n","        # Vitamin B12 & Folate Deficiency\n","        if row['HAEMOGLOBIN'] < 12 and row['MCV'] > 100 and row['MCH'] > 33:\n","            detected.append(\"Vitamin B12 & Folate Deficiency\")\n","\n","        # Chronic Kidney Disease\n","        if row['HAEMOGLOBIN'] < 12 and row['RBC COUNT'] < 4.2 and row['PCV'] < 36 and row['PLATELET COUNT'] < 150000:\n","            detected.append(\"Chronic Kidney Disease\")\n","\n","        # Thalassemia\n","        if row['HAEMOGLOBIN'] < 12 and row['RBC COUNT'] > 5.5 and row['MCV'] < 80 and row['MCH'] < 27:\n","            detected.append(\"Thalassemia\")\n","\n","        # Sepsis\n","        if row['WBC COUNT'] > 12000 and row['NEUTROPHIL'] > 70 and row['LYMPHOCYTE'] < 20 and row['PLATELET COUNT'] < 150000:\n","            detected.append(\"Sepsis\")\n","\n","        # Liver Disease\n","        if row['HAEMOGLOBIN'] < 12 and row['RBC COUNT'] < 4.2 and row['PLATELET COUNT'] < 150000:\n","            detected.append(\"Liver Disease\")\n","\n","        # Dengue\n","        if row['PLATELET COUNT'] < 100000 and row['WBC COUNT'] < 4000:\n","            detected.append(\"Dengue\")\n","\n","        # Malaria\n","        if row['HAEMOGLOBIN'] < 12 and row['RBC COUNT'] < 4.2 and row['PLATELET COUNT'] < 150000:\n","            detected.append(\"Malaria\")\n","\n","        # Polycythemia Vera\n","        # if row['HAEMOGLOBIN'] > 16 and row['RBC COUNT'] > 6.0 and row['PCV'] > 50:\n","        #     detected.append(\"Polycythemia Vera\")\n","\n","        # Aplastic Anemia\n","        if row['HAEMOGLOBIN'] < 10 and row['RBC COUNT'] < 3.5 and row['WBC COUNT'] < 4000 and row['PLATELET COUNT'] < 100000:\n","            detected.append(\"Aplastic Anemia\")\n","\n","        # Leukemia\n","        if (row['WBC COUNT'] > 50000 or row['WBC COUNT'] < 4000) and row['RBC COUNT'] < 4.2 and row['PLATELET COUNT'] < 150000:\n","            detected.append(\"Leukemia\")\n","\n","        # Hyperthyroidism\n","        # if row['RBC COUNT'] > 5.5 and row['MCV'] > 90:\n","        #     detected.append(\"Hyperthyroidism\")\n","\n","        # Multiple Myeloma\n","        if row['HAEMOGLOBIN'] < 12 and row['RBC COUNT'] < 4.2 and row['WBC COUNT'] < 4000 and row['PLATELET COUNT'] < 150000:\n","            detected.append(\"Multiple Myeloma\")\n","\n","        # Myelodysplastic Syndrome\n","        if row['HAEMOGLOBIN'] < 12 and row['RBC COUNT'] < 4.2 and row['WBC COUNT'] < 4000 and row['PLATELET COUNT'] < 150000 and row['RDW-CV'] > 15:\n","            detected.append(\"Myelodysplastic Syndrome\")\n","\n","        # Tuberculosis\n","        # if row['WBC COUNT'] > 11000 and row['NEUTROPHIL'] > 70 and row['MONOCYTE'] > 10:\n","        #     detected.append(\"Tuberculosis\")\n","\n","        # Additional Diseases\n","        # Pernicious Anemia\n","        if row['HAEMOGLOBIN'] < 12 and row['MCV'] > 100:\n","            detected.append(\"Pernicious Anemia\")\n","\n","        # # Dehydration\n","        # if row['HAEMOGLOBIN'] > 16 and row['RBC COUNT'] > 6.0 and row['PCV'] > 50:\n","        #     detected.append(\"Dehydration\")\n","\n","        # General Infection\n","        if row['WBC COUNT'] > 11000:\n","            detected.append(\"General Infection\")\n","\n","        # Hypothyroidism\n","        if row['RBC COUNT'] < 4.2 and row['MCV'] > 90:\n","            detected.append(\"Hypothyroidism\")\n","\n","        # Autoimmune Diseases\n","        if row['WBC COUNT'] < 4000 and row['PLATELET COUNT'] < 150000 and row['RBC COUNT'] < 4.2:\n","            detected.append(\"Possible Autoimmune Disease\")\n","\n","        # # Hemochromatosis\n","        # if row['HAEMOGLOBIN'] > 16 and row['RBC COUNT'] > 6.0:\n","        #     detected.append(\"Hemochromatosis\")\n","\n","        # # Alcoholic Liver Disease\n","        # if row['HAEMOGLOBIN'] < 12 and row['RBC COUNT'] < 4.2 and row['MCV'] > 100 and row['PLATELET COUNT'] < 150000:\n","        #     detected.append(\"Alcoholic Liver Disease\")\n","\n","        conditions.append(\", \".join(detected) if detected else \"No Major Condition Detected\")\n","\n","    df['Detected Conditions'] = conditions\n","    return df\n","\n","# Load dataset\n","file_path = \"formatted_data.csv\"\n","df = pd.read_csv(file_path)\n","\n","# Process dataset\n","df = detect_diseases(df)\n","\n","# Count occurrences of each disease\n","disease_counts = df['Detected Conditions'].str.split(', ').explode().value_counts()\n","print(disease_counts)\n","\n","# Save the updated dataset\n","df.to_csv(\"output_with_diseases.csv\", index=False)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WvJED-APf7fE","executionInfo":{"status":"ok","timestamp":1743703913856,"user_tz":-330,"elapsed":2013,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"f84e4e31-5993-49b1-a404-1d81b297b3d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Detected Conditions\n","General Infection                  5467\n","No Major Condition Detected        5432\n","Hemolytic Anemia                   4664\n","Hypothyroidism                     2689\n","Liver Disease                      1454\n","Malaria                            1454\n","Chronic Kidney Disease             1410\n","Iron Deficiency Anemia             1012\n","Leukemia                            395\n","Possible Autoimmune Disease         377\n","Multiple Myeloma                    367\n","Pernicious Anemia                   359\n","Sepsis                              347\n","Myelodysplastic Syndrome            318\n","Dengue                              303\n","Aplastic Anemia                     228\n","Thalassemia                         207\n","Vitamin B12 & Folate Deficiency     157\n","Name: count, dtype: int64\n"]}]},{"cell_type":"markdown","source":["**Step 18**"],"metadata":{"id":"b3xFWzk_4G0M"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Define dataset path\n","file_path = \"output_with_diseases.csv\"  # Change this path as needed\n","\n","# Load dataset\n","df = pd.read_csv(file_path)\n","\n","# Process dataset to detect diseases\n","df = detect_diseases(df)\n","\n","# Convert 'Detected Conditions' column to multi-label format\n","disease_labels = [\n","    \"No Major Condition Detected\",\"Iron Deficiency Anemia\", \"Hemolytic Anemia\", \"Vitamin B12 & Folate Deficiency\", \"Chronic Kidney Disease\", \"Thalassemia\", \"Sepsis\", \"Liver Disease\", \"Dengue\", \"Malaria\", \"Aplastic Anemia\", \"Leukemia\", \"Multiple Myeloma\", \"Myelodysplastic Syndrome\", \"Pernicious Anemia\",  \"General Infection\", \"Hypothyroidism\", \"Possible Autoimmune Disease\"\n","]\n","\n","# Initialize disease columns with 0\n","for disease in disease_labels:\n","    df[disease] = 0\n","\n","# Set value to 1 if disease is present in 'Detected Conditions'\n","for index, row in df.iterrows():\n","    detected_conditions = row['Detected Conditions'].split(', ')\n","    for disease in detected_conditions:\n","        if disease in disease_labels:\n","            df.at[index, disease] = 1\n","\n","# Drop unnecessary columns (keeping only numerical features + labels)\n","columns_to_keep = [col for col in df.columns if col in disease_labels or col not in ['MRNO', 'Detected Conditions']] # remove MRNO if you need not to remove that column\n","df = df[columns_to_keep]\n","\n","# Save the transformed dataset\n","df.to_csv(\"multi_label_dataset.csv\", index=False)\n","\n","print(\"Dataset formatted for multi-label classification and saved as 'multi_label_dataset.csv'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-478KDr4kx5w","executionInfo":{"status":"ok","timestamp":1743707299681,"user_tz":-330,"elapsed":3721,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"b6541f93-de66-4ead-a901-02f5625f8942"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset formatted for multi-label classification and saved as 'multi_label_dataset.csv'.\n"]}]},{"cell_type":"markdown","source":["**Step 19**"],"metadata":{"id":"Z4nLYfZWJLKU"}},{"cell_type":"code","source":["# Accuracy is too high as we found out the output using rule based query and ml model learns that rule instead of finding patterns thus manually introducing some variations"],"metadata":{"id":"RFZjkw7x3s1r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Load the dataset\n","file_path = 'Final_Org_2.csv'  # Replace with your actual file path\n","df = pd.read_csv(file_path)\n","\n","# List of columns to modify\n","columns_to_modify = [\n","    'No Major Condition Detected', 'Iron Deficiency Anemia', 'Hemolytic Anemia',\n","    'Vitamin B12 & Folate Deficiency', 'Chronic Kidney Disease', 'Thalassemia',\n","    'Sepsis', 'Liver Disease', 'Dengue', 'Malaria', 'Aplastic Anemia',\n","    'Leukemia', 'Multiple Myeloma', 'Myelodysplastic Syndrome',\n","    'Pernicious Anemia', 'General Infection', 'Hypothyroidism',\n","    'Possible Autoimmune Disease'\n","]\n","\n","# Ensure columns exist in the dataset\n","columns_to_modify = [col for col in columns_to_modify if col in df.columns]\n","\n","# Randomly select 20% of rows for each column and flip their values\n","for column in columns_to_modify:\n","    # Get indices of rows where the column has either 0 or 1\n","    valid_indices = df.index[df[column].isin([0, 1])].tolist()\n","\n","    # Randomly select 20% of these indices\n","    num_to_flip = int(0.1 * len(valid_indices))\n","    indices_to_flip = np.random.choice(valid_indices, size=num_to_flip, replace=False)\n","\n","    # Flip the values (0 -> 1 and 1 -> 0)\n","    df.loc[indices_to_flip, column] = df.loc[indices_to_flip, column].apply(lambda x: 1 - x)\n","\n","# Save the modified DataFrame to a new CSV file\n","output_file_path = \"modified_Final_1.csv\"\n","df.to_csv(output_file_path, index=False)\n","\n","print(f\"Modified data saved to {output_file_path}\")\n"],"metadata":{"id":"SMQJfz1wJcwg","executionInfo":{"status":"ok","timestamp":1743839175089,"user_tz":-330,"elapsed":387,"user":{"displayName":"PRANJAL AGRAWAL","userId":"04881223367016190221"}},"outputId":"4d9015a0-2fc5-46a9-dd13-c4b830f40570","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Modified data saved to modified_Final_1.csv\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YAIPNlyqLULT"},"execution_count":null,"outputs":[]}]}